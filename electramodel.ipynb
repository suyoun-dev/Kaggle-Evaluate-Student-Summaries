{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import AutoTokenizer, AutoModel\nfrom transformers import get_linear_schedule_with_warmup\nfrom transformers import Trainer, TrainingArguments\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, Dataset\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport torch.nn.functional as F\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:21:30.299896Z","iopub.execute_input":"2023-09-28T13:21:30.300321Z","iopub.status.idle":"2023-09-28T13:21:43.253226Z","shell.execute_reply.started":"2023-09-28T13:21:30.300281Z","shell.execute_reply":"2023-09-28T13:21:43.252198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda:0\")\n    print(\"GPU is available and being used\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU is not available, using CPU instead\")","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:21:43.255417Z","iopub.execute_input":"2023-09-28T13:21:43.256827Z","iopub.status.idle":"2023-09-28T13:21:43.328267Z","shell.execute_reply.started":"2023-09-28T13:21:43.256787Z","shell.execute_reply":"2023-09-28T13:21:43.327071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nos.environ['CUDA_VISIBLE_DEVICES']  = \"0\"\n#model = nn.DataParallel(model, output_device=0)\ntorch.cuda.device_count()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:21:43.332108Z","iopub.execute_input":"2023-09-28T13:21:43.332529Z","iopub.status.idle":"2023-09-28T13:21:43.343200Z","shell.execute_reply.started":"2023-09-28T13:21:43.332499Z","shell.execute_reply":"2023-09-28T13:21:43.342087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompts_train = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv\")\nprompts_test = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv\")\n\nsummaries_train = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv\")\nsummaries_test = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv\")\n\nsample_submission = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/sample_submission.csv\")\n\nprompts_train","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:21:43.345215Z","iopub.execute_input":"2023-09-28T13:21:43.345712Z","iopub.status.idle":"2023-09-28T13:21:43.486540Z","shell.execute_reply.started":"2023-09-28T13:21:43.345673Z","shell.execute_reply":"2023-09-28T13:21:43.485490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataframe 병합, prompt id 기준으로 각 아이디에 맞는 prompts_train, test 내용을 왼쪽에 붙임\ntrain = summaries_train.merge(prompts_train, how=\"left\", on=\"prompt_id\")\ntest = summaries_test.merge(prompts_test, how=\"left\", on=\"prompt_id\")\n\ntrain","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:21:43.490013Z","iopub.execute_input":"2023-09-28T13:21:43.491824Z","iopub.status.idle":"2023-09-28T13:21:43.533070Z","shell.execute_reply.started":"2023-09-28T13:21:43.491785Z","shell.execute_reply":"2023-09-28T13:21:43.532071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['merged_text'] = 'text '+train['text'] + ' prompt_question ' + train['prompt_question'] + ' prompt_title '+train['prompt_title']+ ' prompt_text '+train['prompt_text']\ntrain['merged_text'].head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:21:43.535391Z","iopub.execute_input":"2023-09-28T13:21:43.536523Z","iopub.status.idle":"2023-09-28T13:21:43.607740Z","shell.execute_reply.started":"2023-09-28T13:21:43.536486Z","shell.execute_reply":"2023-09-28T13:21:43.606613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['merged_text'] = 'text '+ test['text'] + ' prompt_question ' + test['prompt_question'] + ' prompt_title '+ test['prompt_title']+ ' prompt_text '+ test['prompt_text']\ntest['merged_text'].head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:21:43.609841Z","iopub.execute_input":"2023-09-28T13:21:43.610313Z","iopub.status.idle":"2023-09-28T13:21:43.622848Z","shell.execute_reply.started":"2023-09-28T13:21:43.610278Z","shell.execute_reply":"2023-09-28T13:21:43.621705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/electra/base-discriminator')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:21:43.624606Z","iopub.execute_input":"2023-09-28T13:21:43.625101Z","iopub.status.idle":"2023-09-28T13:21:43.725733Z","shell.execute_reply.started":"2023-09-28T13:21:43.625067Z","shell.execute_reply":"2023-09-28T13:21:43.724700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataset(df):\n    encoding = tokenizer(list(df['merged_text']),\n                   padding=True,\n                   truncation=True,\n                   max_length=512,\n                   return_tensors=\"pt\")\n    content = torch.tensor(df['content'], dtype=torch.float32)\n    wording = torch.tensor(df['wording'], dtype=torch.float32)\n    labels = torch.dstack((content, wording)).squeeze()\n    dataset = TensorDataset(encoding['input_ids'], encoding['attention_mask'], labels)\n    return dataset\n\nds = get_dataset(train)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:21:43.727390Z","iopub.execute_input":"2023-09-28T13:21:43.727763Z","iopub.status.idle":"2023-09-28T13:22:05.299646Z","shell.execute_reply.started":"2023-09-28T13:21:43.727713Z","shell.execute_reply":"2023-09-28T13:22:05.298617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''class ElectraDataset(torch.utils.data.Dataset) :\n  def __init__(self, contents, wordings, tokenizer, max_length=512):\n    self.documents = documents\n    self.contents = contents\n    self.wordings = wordings\n    self.tokenizer = tokenizer\n    self.max_length = max_length\n    #self.encodings = encoding\n    #self.labels = labels\n\n  def __len__(self): return len(self.documents)\n\n  def __getitem__(self, idx):\n    document = self.documents\n    content = self.contents\n    wording = self.wordings\n\n    # Tokenize the document\n    encoding = self.tokenizer(str(document),\n                   padding=True,\n                   truncation=True,\n                   max_length=self.max_length,\n                   return_tensors=\"pt\")\n    \n    input_ids = encoding['input_ids'].squeeze()\n    attention_mask = encoding['attention_mask'].squeeze()\n\n    content_tensor = torch.tensor(content, dtype=torch.float32)\n    wording_tensor = torch.tensor(wording, dtype=torch.float32)\n    print(content_tensor.size())\n    labels = torch.dstack([content_tensor, wording_tensor]).squeeze()\n\n    dataset = TensorDataset(encoding['input_ids'], encoding['attention_mask'], labels)\n\n    return dataset\n    \n    {\n        'input_ids': input_ids,\n        'attention_mask': attention_mask,\n        'labels': labels\n    }'''","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:22:05.301215Z","iopub.execute_input":"2023-09-28T13:22:05.301674Z","iopub.status.idle":"2023-09-28T13:22:05.311588Z","shell.execute_reply.started":"2023-09-28T13:22:05.301639Z","shell.execute_reply":"2023-09-28T13:22:05.310607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, random_split","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:22:05.313066Z","iopub.execute_input":"2023-09-28T13:22:05.314662Z","iopub.status.idle":"2023-09-28T13:22:05.323067Z","shell.execute_reply.started":"2023-09-28T13:22:05.314622Z","shell.execute_reply":"2023-09-28T13:22:05.322057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset, val_dataset = random_split(ds, [0.8, 0.2]) #dataset\nprint(len(train_dataset))\nprint(len(val_dataset))","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:22:05.324444Z","iopub.execute_input":"2023-09-28T13:22:05.325356Z","iopub.status.idle":"2023-09-28T13:22:05.338889Z","shell.execute_reply.started":"2023-09-28T13:22:05.325328Z","shell.execute_reply":"2023-09-28T13:22:05.337895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(\n            train_dataset,\n            batch_size = 16\n)\n\nval_dataloader = DataLoader(\n            val_dataset,\n            batch_size = 16\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:22:05.340423Z","iopub.execute_input":"2023-09-28T13:22:05.341013Z","iopub.status.idle":"2023-09-28T13:22:05.347747Z","shell.execute_reply.started":"2023-09-28T13:22:05.340979Z","shell.execute_reply":"2023-09-28T13:22:05.346637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import ElectraForSequenceClassification, ElectraTokenizer, ElectraModel","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:22:05.352743Z","iopub.execute_input":"2023-09-28T13:22:05.353083Z","iopub.status.idle":"2023-09-28T13:22:05.365758Z","shell.execute_reply.started":"2023-09-28T13:22:05.353056Z","shell.execute_reply":"2023-09-28T13:22:05.365128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ElectraFineTuning(nn.Module):\n    def __init__(self):\n        super(ElectraFineTuning, self).__init__()\n        self.electra = ElectraModel.from_pretrained(\"/kaggle/input/electra/base-discriminator\").to(device)\n\n        self.dropout = nn.Dropout(0.1)\n        self.linear1 = nn.Linear(768, 128)\n        self.linear2 = nn.Linear(128, 2)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.electra(input_ids, attention_mask=attention_mask)\n        hidden_states = outputs.last_hidden_state\n        pooled_output = torch.mean(hidden_states, dim=1)\n        pooled_output = self.dropout(pooled_output)\n        output = self.linear1(pooled_output)\n        output = nn.ReLU()(output)\n        output = self.linear2(output)\n        return output\n\nnum_labels = 2  # Replace with the number of labels in your dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:22:05.366854Z","iopub.execute_input":"2023-09-28T13:22:05.367882Z","iopub.status.idle":"2023-09-28T13:22:05.376443Z","shell.execute_reply.started":"2023-09-28T13:22:05.367851Z","shell.execute_reply":"2023-09-28T13:22:05.375603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ElectraFineTuning().to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:22:05.378015Z","iopub.execute_input":"2023-09-28T13:22:05.378432Z","iopub.status.idle":"2023-09-28T13:22:17.816202Z","shell.execute_reply.started":"2023-09-28T13:22:05.378400Z","shell.execute_reply":"2023-09-28T13:22:17.815104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:22:17.817735Z","iopub.execute_input":"2023-09-28T13:22:17.818111Z","iopub.status.idle":"2023-09-28T13:22:17.827564Z","shell.execute_reply.started":"2023-09-28T13:22:17.818072Z","shell.execute_reply":"2023-09-28T13:22:17.826581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define your loss function (e.g., CrossEntropyLoss)\nloss_fn = nn.CrossEntropyLoss()\n\n# Define the number of training epochs\nnum_epochs = 40\n\n# Define your optimizer and learning rate scheduler\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8)\ntotal_steps = len(train_dataloader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n\n# Create data loaders for training and validation\n#train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n#validation_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:22:17.829073Z","iopub.execute_input":"2023-09-28T13:22:17.829741Z","iopub.status.idle":"2023-09-28T13:22:17.839403Z","shell.execute_reply.started":"2023-09-28T13:22:17.829706Z","shell.execute_reply":"2023-09-28T13:22:17.838597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:22:17.840837Z","iopub.execute_input":"2023-09-28T13:22:17.841461Z","iopub.status.idle":"2023-09-28T13:22:17.850644Z","shell.execute_reply.started":"2023-09-28T13:22:17.841427Z","shell.execute_reply":"2023-09-28T13:22:17.849722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping_patience = 3  # Stop training if validation loss doesn't improve for 3 consecutive epochs\nmin_val_loss = np.inf\nno_improvement_count = 0","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:22:17.852120Z","iopub.execute_input":"2023-09-28T13:22:17.852788Z","iopub.status.idle":"2023-09-28T13:22:17.860978Z","shell.execute_reply.started":"2023-09-28T13:22:17.852754Z","shell.execute_reply":"2023-09-28T13:22:17.859862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\nmodel.train()\npatience = 0\n\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    for step, (input_ids, attention_mask, labels) in enumerate(train_dataloader):\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask)\n        #logits = outputs.logits\n\n        #print(outputs)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        if step % 100 == 0:\n            print(\"Epoch {}, Step {}, Loss: {}\".format(epoch+1, step, loss.item()))\n\n        running_loss += loss.item()\n\n    print(f\"Epoch {epoch+1} Loss: {running_loss / len(train_dataloader)}\")\n\n    # Validation loop\n    model.eval()\n    all_labels = []\n    all_predictions = []\n\n    with torch.no_grad():\n        val_loss = 0.0\n        for val_step, (input_ids, attention_mask, labels) in enumerate(val_dataloader):\n            input_ids = input_ids.to(device)\n            attention_mask = attention_mask.to(device)\n            labels = labels.to(device)\n\n            val_outputs = model(input_ids, attention_mask)\n            val_loss += loss_fn(val_outputs, labels)\n        avg_loss = val_loss / len(val_dataloader)\n        print(f\"Validation Loss: {avg_loss}\")\n\n        if avg_loss < min_val_loss:\n            patience = 0\n            min_val_loss = avg_loss\n            torch.save(model.state_dict(), '/kaggle/working/model.pt')\n            print(f'saving model with score: {avg_loss}')\n\n    patience += 1\n    if patience >= 10:\n            print('Early Stopping trigerred on epoch: {}')\n            break\n\n    model.train()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:22:17.864955Z","iopub.execute_input":"2023-09-28T13:22:17.865271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ElectraFineTuning().to(device)\ncheckpoint.load_state_dict(torch.load('/kaggle/working/model.pt'))\n\n\nmodel.eval()\n\nenc = tokenizer(list(test['merged_text']),\n                   padding=True,\n                   truncation=True,\n                   max_length=512,\n                   return_tensors=\"pt\")\n\ntest_ds = TensorDataset(enc['input_ids'], enc['attention_mask'])\ntest_dataloader = torch.utils.data.DataLoader(test_ds, batch_size=16, shuffle=False)\n\n\npredictions = []\nwith torch.no_grad():\n    for input_ids, attention_mask in test_dataloader:\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n\n        outputs = model(input_ids, attention_mask)\n        predictions.extend(outputs.cpu().numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame({\n    'student_id': test['student_id'],\n    'content': [pred[0] for pred in predictions],\n    'wording': [pred[1] for pred in predictions]\n})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)\nsubmission_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}