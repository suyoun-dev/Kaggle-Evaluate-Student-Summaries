{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-26T04:46:41.713648Z","iopub.execute_input":"2023-09-26T04:46:41.714133Z","iopub.status.idle":"2023-09-26T04:46:42.208294Z","shell.execute_reply.started":"2023-09-26T04:46:41.714053Z","shell.execute_reply":"2023-09-26T04:46:42.207340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import AutoTokenizer, AutoModel,AutoModelForSequenceClassification\nimport pandas as pd\nimport torch.nn.functional as F\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:03:03.078821Z","iopub.execute_input":"2023-09-26T12:03:03.079317Z","iopub.status.idle":"2023-09-26T12:03:05.684974Z","shell.execute_reply.started":"2023-09-26T12:03:03.079216Z","shell.execute_reply":"2023-09-26T12:03:05.683930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda:0\")\n    print(\"GPU is available and being used\", device)\nelse:\n    print(\"GPU is not available, using CPU instead\")","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:03:05.687311Z","iopub.execute_input":"2023-09-26T12:03:05.687879Z","iopub.status.idle":"2023-09-26T12:03:05.763855Z","shell.execute_reply.started":"2023-09-26T12:03:05.687842Z","shell.execute_reply":"2023-09-26T12:03:05.762878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nos.environ['CUDA_VISIBLE_DEVICES']  = \"0\"\n#model = nn.DataParallel(model, output_device=0)\ntorch.cuda.device_count()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:03:05.765528Z","iopub.execute_input":"2023-09-26T12:03:05.766371Z","iopub.status.idle":"2023-09-26T12:03:05.793184Z","shell.execute_reply.started":"2023-09-26T12:03:05.766316Z","shell.execute_reply":"2023-09-26T12:03:05.792152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompts_train = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv\")\nprompts_test = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv\")\n\nsummaries_train = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv\")\nsummaries_test = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv\")\n\nsample_submission = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/sample_submission.csv\")\n\nprompts_train","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:03:05.795780Z","iopub.execute_input":"2023-09-26T12:03:05.796586Z","iopub.status.idle":"2023-09-26T12:03:05.946623Z","shell.execute_reply.started":"2023-09-26T12:03:05.796551Z","shell.execute_reply":"2023-09-26T12:03:05.945693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataframe 병합, prompt id 기준으로 각 아이디에 맞는 prompts_train, test 내용을 왼쪽에 붙임\ntrain = summaries_train.merge(prompts_train, how=\"left\", on=\"prompt_id\")\ntest = summaries_test.merge(prompts_test, how=\"left\", on=\"prompt_id\")\n\ntrain","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:03:05.948119Z","iopub.execute_input":"2023-09-26T12:03:05.948667Z","iopub.status.idle":"2023-09-26T12:03:05.993159Z","shell.execute_reply.started":"2023-09-26T12:03:05.948633Z","shell.execute_reply":"2023-09-26T12:03:05.992146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['merged_text'] = 'text '+train['text'] + ' prompt_question ' + train['prompt_question'] + ' prompt_title '+train['prompt_title']+ ' prompt_text '+train['prompt_text']\ntrain['merged_text'].head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:03:05.994660Z","iopub.execute_input":"2023-09-26T12:03:05.995026Z","iopub.status.idle":"2023-09-26T12:03:06.069155Z","shell.execute_reply.started":"2023-09-26T12:03:05.994991Z","shell.execute_reply":"2023-09-26T12:03:06.068213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['merged_text'] = 'text '+ test['text'] + ' prompt_question ' + test['prompt_question'] + ' prompt_title '+ test['prompt_title']+ ' prompt_text '+ test['prompt_text']\ntest['merged_text'].head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:03:06.070884Z","iopub.execute_input":"2023-09-26T12:03:06.071295Z","iopub.status.idle":"2023-09-26T12:03:06.084106Z","shell.execute_reply.started":"2023-09-26T12:03:06.071261Z","shell.execute_reply":"2023-09-26T12:03:06.083052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    def __init__(self):\n        self.model_name = '/kaggle/input/roberta-base'\n        self.tokenizer_path = '/kaggle/input/roberta-base'\n        self.batch_size = 16\n        self.num_epochs = 40\n        self.token_max = 512\n        self.learning_rate = 1e-5\n        self.model_save_path = '/kaggle/working/model.pt'\n\ncfg = CFG()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:03:49.142790Z","iopub.execute_input":"2023-09-26T12:03:49.143246Z","iopub.status.idle":"2023-09-26T12:03:49.159928Z","shell.execute_reply.started":"2023-09-26T12:03:49.143195Z","shell.execute_reply":"2023-09-26T12:03:49.158684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from itertools import chain\nfrom torch.utils.data import TensorDataset, DataLoader, random_split","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:03:49.161827Z","iopub.execute_input":"2023-09-26T12:03:49.162092Z","iopub.status.idle":"2023-09-26T12:03:49.170757Z","shell.execute_reply.started":"2023-09-26T12:03:49.162068Z","shell.execute_reply":"2023-09-26T12:03:49.169740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(cfg.tokenizer_path)\nbase_model = AutoModel.from_pretrained(cfg.model_name).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:03:49.172120Z","iopub.execute_input":"2023-09-26T12:03:49.172446Z","iopub.status.idle":"2023-09-26T12:03:51.191046Z","shell.execute_reply.started":"2023-09-26T12:03:49.172393Z","shell.execute_reply":"2023-09-26T12:03:51.190032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataset(df):\n    encoding = tokenizer(list(train['merged_text']),\n                   padding=True,\n                   truncation=True,\n                   max_length=cfg.token_max,\n                   return_tensors=\"pt\")\n    content = torch.tensor(df['content'], dtype=torch.float32)\n    wording = torch.tensor(df['wording'], dtype=torch.float32)\n    labels = torch.dstack((content, wording)).squeeze()\n    dataset = TensorDataset(encoding['input_ids'], encoding['attention_mask'], labels)\n    return dataset\n\nds = get_dataset(train)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:03:51.192582Z","iopub.execute_input":"2023-09-26T12:03:51.193248Z","iopub.status.idle":"2023-09-26T12:04:11.623534Z","shell.execute_reply.started":"2023-09-26T12:03:51.193191Z","shell.execute_reply":"2023-09-26T12:04:11.621299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RobertaModel(nn.Module):\n    def __init__(self):\n        super(RobertaModel, self).__init__()\n        self.RobertaModel = AutoModel.from_pretrained('/kaggle/input/roberta-base')\n\n        self.dropout = nn.Dropout(0.1)\n        self.linear1 = nn.Linear(768, 128)\n        self.linear2 = nn.Linear(128, 2)\n\n    def forward(self, input_ids, attention_mask):\n        #print('forward')\n        outputs = self.RobertaModel(input_ids=input_ids, attention_mask=attention_mask) # roberta는 tokentypeid가 없음\n        pooled_output = outputs.pooler_output\n        pooled_output = self.dropout(pooled_output)\n        output = self.linear1(pooled_output)\n        output = nn.ReLU()(output)\n        output = self.linear2(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:04:11.625136Z","iopub.execute_input":"2023-09-26T12:04:11.625982Z","iopub.status.idle":"2023-09-26T12:04:11.635396Z","shell.execute_reply.started":"2023-09-26T12:04:11.625947Z","shell.execute_reply":"2023-09-26T12:04:11.634189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds, val_ds = random_split(ds, [0.8, 0.2])\nprint(len(train_ds))\nprint(len(val_ds))","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:04:11.638025Z","iopub.execute_input":"2023-09-26T12:04:11.638749Z","iopub.status.idle":"2023-09-26T12:04:11.661798Z","shell.execute_reply.started":"2023-09-26T12:04:11.638708Z","shell.execute_reply":"2023-09-26T12:04:11.660596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(\n            train_ds,\n            batch_size = cfg.batch_size\n)\n\nval_dataloader = DataLoader(\n            val_ds,\n            batch_size = cfg.batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:04:11.665900Z","iopub.execute_input":"2023-09-26T12:04:11.666186Z","iopub.status.idle":"2023-09-26T12:04:11.672655Z","shell.execute_reply.started":"2023-09-26T12:04:11.666162Z","shell.execute_reply":"2023-09-26T12:04:11.671691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:04:11.674880Z","iopub.execute_input":"2023-09-26T12:04:11.675376Z","iopub.status.idle":"2023-09-26T12:04:11.686213Z","shell.execute_reply.started":"2023-09-26T12:04:11.675344Z","shell.execute_reply":"2023-09-26T12:04:11.685135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RobertaModel().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=cfg.learning_rate)\nloss_fn = nn.MSELoss() # RMSE\nmin_val_loss = np.inf","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:04:11.687731Z","iopub.execute_input":"2023-09-26T12:04:11.688119Z","iopub.status.idle":"2023-09-26T12:04:13.205491Z","shell.execute_reply.started":"2023-09-26T12:04:11.688087Z","shell.execute_reply":"2023-09-26T12:04:13.204506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:04:13.207183Z","iopub.execute_input":"2023-09-26T12:04:13.207603Z","iopub.status.idle":"2023-09-26T12:04:13.215798Z","shell.execute_reply.started":"2023-09-26T12:04:13.207567Z","shell.execute_reply":"2023-09-26T12:04:13.214779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:04:13.217536Z","iopub.execute_input":"2023-09-26T12:04:13.218166Z","iopub.status.idle":"2023-09-26T12:04:13.225855Z","shell.execute_reply.started":"2023-09-26T12:04:13.218134Z","shell.execute_reply":"2023-09-26T12:04:13.224680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\nmodel.train()\npatience = 0\n\n# Initialize empty lists to store training and validation loss values\ntrain_losses = []\nval_losses = []\n\nfor epoch in range(cfg.num_epochs):\n    running_loss = 0.0\n    for step, (input_ids, attention_mask, labels) in enumerate(train_dataloader):\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(input_ids, attention_mask)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        if step % 100 == 0:\n            print(\"Epoch {}, Step {}, Loss: {}\".format(epoch+1, step, loss.item()))\n\n        running_loss += loss.item()\n    # Append the average training loss for the epoch to the list\n    train_losses.append(running_loss / len(train_dataloader))\n    print(f\"Epoch {epoch+1} Loss: {running_loss / len(train_dataloader)}\")\n\n    # Validation loop\n    model.eval()\n    with torch.no_grad():\n        val_loss = 0.0\n        for val_step, (input_ids, attention_mask, labels) in enumerate(val_dataloader):\n            input_ids = input_ids.to(device)\n            attention_mask = attention_mask.to(device)\n            labels = labels.to(device)\n\n            val_outputs = model(input_ids, attention_mask)\n            val_loss += loss_fn(val_outputs, labels)\n        avg_loss = val_loss / len(val_dataloader)\n        # Append the validation loss for the epoch to the list\n        val_losses.append(avg_loss)\n        print(f\"Validation Loss: {avg_loss}\")\n\n        if avg_loss < min_val_loss:\n            patience = 0\n            min_val_loss = avg_loss\n            torch.save(model.state_dict(), cfg.model_save_path)\n            print(f'saving model with score: {avg_loss}')\n\n    patience += 1\n    if patience >= 10:\n            print('Early Stopping trigerred on epoch: {}')\n            break\n\n    model.train()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:04:13.227589Z","iopub.execute_input":"2023-09-26T12:04:13.228312Z","iopub.status.idle":"2023-09-26T12:25:11.364321Z","shell.execute_reply.started":"2023-09-26T12:04:13.228278Z","shell.execute_reply":"2023-09-26T12:25:11.363267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the NumPy arrays to the CPU\n#train_losses_cpu = [t.cpu().numpy() for t in train_losses]\n#val_losses_cpu = [v.cpu().numpy() for v in val_losses]","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:25:11.365731Z","iopub.execute_input":"2023-09-26T12:25:11.366381Z","iopub.status.idle":"2023-09-26T12:25:11.894212Z","shell.execute_reply.started":"2023-09-26T12:25:11.366344Z","shell.execute_reply":"2023-09-26T12:25:11.892988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the loss values\n'''plt.figure(figsize=(10, 5))\nplt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\nplt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Loss Over Epochs')\nplt.show()'''","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:25:11.895256Z","iopub.status.idle":"2023-09-26T12:25:11.895632Z","shell.execute_reply.started":"2023-09-26T12:25:11.895442Z","shell.execute_reply":"2023-09-26T12:25:11.895459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = RobertaModel().to(device)\ncheckpoint.load_state_dict(torch.load(cfg.model_save_path))\n#model.load_state_dict(torch.load(cfg.model_save_path, map_location='cuda:0'), strict=False)\n\n'''if isinstance(model, nn.DataParallel):\n  model.load_state_dict(torch.load('model.pt'))\nelse:\n  state_dict = torch.load(cfg.model_save_path)\n  new_state_dict = OrderedDict()\n  for k, v in state_dict.items():\n    name = k[7:] # remove module\n    new_state_dict[name] = v\n  model.load_state_dict(new_state_dict)'''\n\nmodel.eval()\n\nenc = tokenizer(list(test['merged_text']),\n                   padding=True,\n                   truncation=True,\n                   max_length=cfg.token_max,\n                   return_tensors=\"pt\")\n\ntest_ds = TensorDataset(enc['input_ids'], enc['attention_mask'])\ntest_dataloader = torch.utils.data.DataLoader(test_ds, batch_size=16, shuffle=False)\n\n\npredictions = []\nwith torch.no_grad():\n    for input_ids, attention_mask in test_dataloader:\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n\n        outputs = model(input_ids, attention_mask)\n        predictions.extend(outputs.cpu().numpy())","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:25:30.757335Z","iopub.execute_input":"2023-09-26T12:25:30.757709Z","iopub.status.idle":"2023-09-26T12:25:32.614322Z","shell.execute_reply.started":"2023-09-26T12:25:30.757678Z","shell.execute_reply":"2023-09-26T12:25:32.613211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame({\n    'student_id': test['student_id'],\n    'content': [pred[0] for pred in predictions],\n    'wording': [pred[1] for pred in predictions]\n})","metadata":{"execution":{"iopub.status.busy":"2023-09-26T12:25:35.204650Z","iopub.execute_input":"2023-09-26T12:25:35.205026Z","iopub.status.idle":"2023-09-26T12:25:35.212417Z","shell.execute_reply.started":"2023-09-26T12:25:35.204994Z","shell.execute_reply":"2023-09-26T12:25:35.211235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2023-09-26T07:53:57.423823Z","iopub.execute_input":"2023-09-26T07:53:57.424239Z","iopub.status.idle":"2023-09-26T07:53:57.449846Z","shell.execute_reply.started":"2023-09-26T07:53:57.424208Z","shell.execute_reply":"2023-09-26T07:53:57.448143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}