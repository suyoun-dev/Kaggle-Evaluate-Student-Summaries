{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-26T02:57:09.347723Z","iopub.status.idle":"2023-08-26T02:57:09.350149Z","shell.execute_reply.started":"2023-08-26T02:57:09.349891Z","shell.execute_reply":"2023-08-26T02:57:09.349915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reference: Bert Tokenizer + Fine-Tuning Model\nhttps://www.kaggle.com/code/theodorospsarras/bert-tokenizer-fine-tuning-model/input","metadata":{}},{"cell_type":"code","source":"#!pip install torch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import AutoTokenizer, AutoModel,AutoModelForSequenceClassification\nimport pandas as pd\nimport torch.nn.functional as F\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-08-26T13:19:08.411141Z","iopub.execute_input":"2023-08-26T13:19:08.411469Z","iopub.status.idle":"2023-08-26T13:19:14.825104Z","shell.execute_reply.started":"2023-08-26T13:19:08.411439Z","shell.execute_reply":"2023-08-26T13:19:14.824109Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#import os\n\n#os.environ['CUDA_VISIBLE_DEVICES']  = \"0\"\n\n#torch.cuda.device_count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompts_train = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv\")\nprompts_test = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv\")\n\nsummaries_train = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv\")\nsummaries_test = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv\")\n\nsample_submission = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/sample_submission.csv\")\n\nprompts_train","metadata":{"execution":{"iopub.status.busy":"2023-08-26T13:19:14.827207Z","iopub.execute_input":"2023-08-26T13:19:14.827821Z","iopub.status.idle":"2023-08-26T13:19:14.949962Z","shell.execute_reply.started":"2023-08-26T13:19:14.827787Z","shell.execute_reply":"2023-08-26T13:19:14.949046Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"  prompt_id                                    prompt_question  \\\n0    39c16e  Summarize at least 3 elements of an ideal trag...   \n1    3b9047  In complete sentences, summarize the structure...   \n2    814d6b  Summarize how the Third Wave developed over su...   \n3    ebad26  Summarize the various ways the factory would u...   \n\n                prompt_title  \\\n0                 On Tragedy   \n1  Egyptian Social Structure   \n2             The Third Wave   \n3    Excerpt from The Jungle   \n\n                                         prompt_text  \n0  Chapter 13 \\r\\nAs the sequel to what has alrea...  \n1  Egyptian society was structured like a pyramid...  \n2  Background \\r\\nThe Third Wave experiment took ...  \n3  With one member trimming beef in a cannery, an...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3b9047</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>814d6b</td>\n      <td>Summarize how the Third Wave developed over su...</td>\n      <td>The Third Wave</td>\n      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ebad26</td>\n      <td>Summarize the various ways the factory would u...</td>\n      <td>Excerpt from The Jungle</td>\n      <td>With one member trimming beef in a cannery, an...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"1. prompt 파일과 train/test 파일 merge 하기","metadata":{}},{"cell_type":"code","source":"# dataframe 병합, prompt id 기준으로 각 아이디에 맞는 prompts_train, test 내용을 왼쪽에 붙임\ntrain = summaries_train.merge(prompts_train, how=\"left\", on=\"prompt_id\")\ntest = summaries_test.merge(prompts_test, how=\"left\", on=\"prompt_id\")\n\ntrain","metadata":{"execution":{"iopub.status.busy":"2023-08-26T13:19:14.952506Z","iopub.execute_input":"2023-08-26T13:19:14.953153Z","iopub.status.idle":"2023-08-26T13:19:14.987064Z","shell.execute_reply.started":"2023-08-26T13:19:14.953119Z","shell.execute_reply":"2023-08-26T13:19:14.986043Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"        student_id prompt_id  \\\n0     000e8c3c7ddb    814d6b   \n1     0020ae56ffbf    ebad26   \n2     004e978e639e    3b9047   \n3     005ab0199905    3b9047   \n4     0070c9e7af47    814d6b   \n...            ...       ...   \n7160  ff7c7e70df07    ebad26   \n7161  ffc34d056498    3b9047   \n7162  ffd1576d2e1b    3b9047   \n7163  ffe4a98093b2    39c16e   \n7164  fffbccfd8a08    ebad26   \n\n                                                   text   content   wording  \\\n0     The third wave was an experimentto see how peo...  0.205683  0.380538   \n1     They would rub it up with soda to make the sme... -0.548304  0.506755   \n2     In Egypt, there were many occupations and soci...  3.128928  4.231226   \n3     The highest class was Pharaohs these people we... -0.210614 -0.471415   \n4     The Third Wave developed  rapidly because the ...  3.272894  3.219757   \n...                                                 ...       ...       ...   \n7160  They used all sorts of chemical concoctions to...  0.205683  0.380538   \n7161  The lowest classes are slaves and farmers slav... -0.308448  0.048171   \n7162             they sorta made people start workin... -1.408180 -0.493603   \n7163  An ideal tragety has three elements that make ... -0.393310  0.627128   \n7164  The meat would smell sour but the would \"rub i...  1.771596  0.547742   \n\n                                        prompt_question  \\\n0     Summarize how the Third Wave developed over su...   \n1     Summarize the various ways the factory would u...   \n2     In complete sentences, summarize the structure...   \n3     In complete sentences, summarize the structure...   \n4     Summarize how the Third Wave developed over su...   \n...                                                 ...   \n7160  Summarize the various ways the factory would u...   \n7161  In complete sentences, summarize the structure...   \n7162  In complete sentences, summarize the structure...   \n7163  Summarize at least 3 elements of an ideal trag...   \n7164  Summarize the various ways the factory would u...   \n\n                   prompt_title  \\\n0                The Third Wave   \n1       Excerpt from The Jungle   \n2     Egyptian Social Structure   \n3     Egyptian Social Structure   \n4                The Third Wave   \n...                         ...   \n7160    Excerpt from The Jungle   \n7161  Egyptian Social Structure   \n7162  Egyptian Social Structure   \n7163                 On Tragedy   \n7164    Excerpt from The Jungle   \n\n                                            prompt_text  \n0     Background \\r\\nThe Third Wave experiment took ...  \n1     With one member trimming beef in a cannery, an...  \n2     Egyptian society was structured like a pyramid...  \n3     Egyptian society was structured like a pyramid...  \n4     Background \\r\\nThe Third Wave experiment took ...  \n...                                                 ...  \n7160  With one member trimming beef in a cannery, an...  \n7161  Egyptian society was structured like a pyramid...  \n7162  Egyptian society was structured like a pyramid...  \n7163  Chapter 13 \\r\\nAs the sequel to what has alrea...  \n7164  With one member trimming beef in a cannery, an...  \n\n[7165 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000e8c3c7ddb</td>\n      <td>814d6b</td>\n      <td>The third wave was an experimentto see how peo...</td>\n      <td>0.205683</td>\n      <td>0.380538</td>\n      <td>Summarize how the Third Wave developed over su...</td>\n      <td>The Third Wave</td>\n      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0020ae56ffbf</td>\n      <td>ebad26</td>\n      <td>They would rub it up with soda to make the sme...</td>\n      <td>-0.548304</td>\n      <td>0.506755</td>\n      <td>Summarize the various ways the factory would u...</td>\n      <td>Excerpt from The Jungle</td>\n      <td>With one member trimming beef in a cannery, an...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>004e978e639e</td>\n      <td>3b9047</td>\n      <td>In Egypt, there were many occupations and soci...</td>\n      <td>3.128928</td>\n      <td>4.231226</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>005ab0199905</td>\n      <td>3b9047</td>\n      <td>The highest class was Pharaohs these people we...</td>\n      <td>-0.210614</td>\n      <td>-0.471415</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0070c9e7af47</td>\n      <td>814d6b</td>\n      <td>The Third Wave developed  rapidly because the ...</td>\n      <td>3.272894</td>\n      <td>3.219757</td>\n      <td>Summarize how the Third Wave developed over su...</td>\n      <td>The Third Wave</td>\n      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7160</th>\n      <td>ff7c7e70df07</td>\n      <td>ebad26</td>\n      <td>They used all sorts of chemical concoctions to...</td>\n      <td>0.205683</td>\n      <td>0.380538</td>\n      <td>Summarize the various ways the factory would u...</td>\n      <td>Excerpt from The Jungle</td>\n      <td>With one member trimming beef in a cannery, an...</td>\n    </tr>\n    <tr>\n      <th>7161</th>\n      <td>ffc34d056498</td>\n      <td>3b9047</td>\n      <td>The lowest classes are slaves and farmers slav...</td>\n      <td>-0.308448</td>\n      <td>0.048171</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n    </tr>\n    <tr>\n      <th>7162</th>\n      <td>ffd1576d2e1b</td>\n      <td>3b9047</td>\n      <td>they sorta made people start workin...</td>\n      <td>-1.408180</td>\n      <td>-0.493603</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n    </tr>\n    <tr>\n      <th>7163</th>\n      <td>ffe4a98093b2</td>\n      <td>39c16e</td>\n      <td>An ideal tragety has three elements that make ...</td>\n      <td>-0.393310</td>\n      <td>0.627128</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n    </tr>\n    <tr>\n      <th>7164</th>\n      <td>fffbccfd8a08</td>\n      <td>ebad26</td>\n      <td>The meat would smell sour but the would \"rub i...</td>\n      <td>1.771596</td>\n      <td>0.547742</td>\n      <td>Summarize the various ways the factory would u...</td>\n      <td>Excerpt from The Jungle</td>\n      <td>With one member trimming beef in a cannery, an...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7165 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2023-08-26T13:19:14.989501Z","iopub.execute_input":"2023-08-26T13:19:14.989902Z","iopub.status.idle":"2023-08-26T13:19:15.000886Z","shell.execute_reply.started":"2023-08-26T13:19:14.989861Z","shell.execute_reply":"2023-08-26T13:19:14.999898Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"     student_id prompt_id            text prompt_question     prompt_title  \\\n0  000000ffffff    abc123  Example text 1    Summarize...  Example Title 1   \n1  111111eeeeee    def789  Example text 2    Summarize...  Example Title 2   \n2  222222cccccc    abc123  Example text 3    Summarize...  Example Title 1   \n3  333333dddddd    def789  Example text 4    Summarize...  Example Title 2   \n\n        prompt_text  \n0  Heading\\nText...  \n1  Heading\\nText...  \n2  Heading\\nText...  \n3  Heading\\nText...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>abc123</td>\n      <td>Example text 1</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>111111eeeeee</td>\n      <td>def789</td>\n      <td>Example text 2</td>\n      <td>Summarize...</td>\n      <td>Example Title 2</td>\n      <td>Heading\\nText...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>222222cccccc</td>\n      <td>abc123</td>\n      <td>Example text 3</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>def789</td>\n      <td>Example text 4</td>\n      <td>Summarize...</td>\n      <td>Example Title 2</td>\n      <td>Heading\\nText...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['merged_text'] = 'text '+train['text'] + ' prompt_question ' + train['prompt_question'] + ' prompt_title '+train['prompt_title']+ ' prompt_text '+train['prompt_text']\ntrain['merged_text'].head(2)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T13:24:01.314940Z","iopub.execute_input":"2023-08-26T13:24:01.315298Z","iopub.status.idle":"2023-08-26T13:24:01.378524Z","shell.execute_reply.started":"2023-08-26T13:24:01.315269Z","shell.execute_reply":"2023-08-26T13:24:01.377512Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0    text The third wave was an experimentto see ho...\n1    text They would rub it up with soda to make th...\nName: merged_text, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"test['merged_text'] = 'text '+ test['text'] + ' prompt_question ' + test['prompt_question'] + ' prompt_title '+ test['prompt_title']+ ' prompt_text '+ test['prompt_text']\ntest['merged_text'].head(2)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T13:24:27.828201Z","iopub.execute_input":"2023-08-26T13:24:27.829193Z","iopub.status.idle":"2023-08-26T13:24:27.840046Z","shell.execute_reply.started":"2023-08-26T13:24:27.829156Z","shell.execute_reply":"2023-08-26T13:24:27.838965Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0    text Example text 1 prompt_question Summarize....\n1    text Example text 2 prompt_question Summarize....\nName: merged_text, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"class CFG:\n    def __init__(self):\n        self.model_name = '/kaggle/input/hugging-face-models-safe-tensors/bert-base-uncased'\n        self.tokenizer_path = '/kaggle/input/hugging-face-models-safe-tensors/bert-base-uncased'\n        self.batch_size = 16\n        self.num_epochs = 40\n        self.token_max = 512\n        self.learning_rate = 1e-5\n        self.model_save_path = '/kaggle/working/model.pt'\n\ncfg = CFG()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T14:17:05.127959Z","iopub.execute_input":"2023-08-26T14:17:05.128335Z","iopub.status.idle":"2023-08-26T14:17:05.134665Z","shell.execute_reply.started":"2023-08-26T14:17:05.128304Z","shell.execute_reply":"2023-08-26T14:17:05.133591Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from transformers import BertModel, BertTokenizer","metadata":{"execution":{"iopub.status.busy":"2023-08-26T13:24:54.486025Z","iopub.execute_input":"2023-08-26T13:24:54.486380Z","iopub.status.idle":"2023-08-26T13:25:03.350093Z","shell.execute_reply.started":"2023-08-26T13:24:54.486349Z","shell.execute_reply":"2023-08-26T13:25:03.349002Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(cfg.tokenizer_path)\nmodel_deberta = BertModel.from_pretrained(cfg.model_name)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T14:17:07.882048Z","iopub.execute_input":"2023-08-26T14:17:07.882428Z","iopub.status.idle":"2023-08-26T14:17:09.265296Z","shell.execute_reply.started":"2023-08-26T14:17:07.882395Z","shell.execute_reply":"2023-08-26T14:17:09.264205Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from itertools import chain\nfrom torch.utils.data import TensorDataset, DataLoader, random_split","metadata":{"execution":{"iopub.status.busy":"2023-08-26T13:26:09.272462Z","iopub.execute_input":"2023-08-26T13:26:09.272831Z","iopub.status.idle":"2023-08-26T13:26:09.278603Z","shell.execute_reply.started":"2023-08-26T13:26:09.272802Z","shell.execute_reply":"2023-08-26T13:26:09.276967Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def get_dataset(df):\n    encoding = tokenizer(list(train['merged_text']),\n                   padding=True,\n                   truncation=True,\n                   max_length=cfg.token_max,\n                   return_tensors=\"pt\")\n    content = torch.tensor(df['content'], dtype=torch.float32)\n    wording = torch.tensor(df['wording'], dtype=torch.float32)\n    labels = torch.dstack((content, wording)).squeeze()\n    dataset = TensorDataset(encoding['input_ids'], encoding['attention_mask'], labels)\n    return dataset\n\nds = get_dataset(train)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T14:17:09.504622Z","iopub.execute_input":"2023-08-26T14:17:09.505548Z","iopub.status.idle":"2023-08-26T14:20:43.942783Z","shell.execute_reply.started":"2023-08-26T14:17:09.505504Z","shell.execute_reply":"2023-08-26T14:20:43.941723Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class BERT(nn.Module):\n    def __init__(self):\n        super(BERT, self).__init__()\n        self.bert = BertModel.from_pretrained('/kaggle/input/hugging-face-models-safe-tensors/bert-base-uncased')\n\n        self.dropout = nn.Dropout(0.1)\n        self.linear1 = nn.Linear(768, 128)\n        self.linear2 = nn.Linear(128, 2) # 왜 2? content, wording이라?\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        pooled_output = self.dropout(pooled_output)\n        output = self.linear1(pooled_output)\n        output = nn.ReLU()(output)\n        output = self.linear2(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-08-26T14:20:43.944809Z","iopub.execute_input":"2023-08-26T14:20:43.945160Z","iopub.status.idle":"2023-08-26T14:20:43.954432Z","shell.execute_reply.started":"2023-08-26T14:20:43.945127Z","shell.execute_reply":"2023-08-26T14:20:43.953575Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_ds, val_ds = random_split(ds, [0.8, 0.2])\nprint(len(train_ds))\nprint(len(val_ds))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T14:20:43.956048Z","iopub.execute_input":"2023-08-26T14:20:43.956409Z","iopub.status.idle":"2023-08-26T14:20:43.973158Z","shell.execute_reply.started":"2023-08-26T14:20:43.956364Z","shell.execute_reply":"2023-08-26T14:20:43.972221Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"5732\n1433\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataloader = DataLoader(\n            train_ds,  \n            batch_size = cfg.batch_size \n)\n\nval_dataloader = DataLoader(\n            val_ds,  \n            batch_size = cfg.batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T14:20:43.975533Z","iopub.execute_input":"2023-08-26T14:20:43.975880Z","iopub.status.idle":"2023-08-26T14:20:43.982744Z","shell.execute_reply.started":"2023-08-26T14:20:43.975848Z","shell.execute_reply":"2023-08-26T14:20:43.981859Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# installation \n#!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n#!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev","metadata":{"execution":{"iopub.status.busy":"2023-08-24T08:56:15.155892Z","iopub.execute_input":"2023-08-24T08:56:15.156193Z","iopub.status.idle":"2023-08-24T08:56:17.803464Z","shell.execute_reply.started":"2023-08-24T08:56:15.156167Z","shell.execute_reply":"2023-08-24T08:56:17.801903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for TPU\n#import torch_xla\n#import torch_xla.core.xla_model as xm","metadata":{"execution":{"iopub.status.busy":"2023-08-24T08:56:17.807084Z","iopub.execute_input":"2023-08-24T08:56:17.807484Z","iopub.status.idle":"2023-08-24T08:56:17.813108Z","shell.execute_reply.started":"2023-08-24T08:56:17.807449Z","shell.execute_reply":"2023-08-24T08:56:17.812142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#device = xm.xla_device()","metadata":{"execution":{"iopub.status.busy":"2023-08-24T08:56:17.814116Z","iopub.execute_input":"2023-08-24T08:56:17.814379Z","iopub.status.idle":"2023-08-24T08:56:17.826116Z","shell.execute_reply.started":"2023-08-24T08:56:17.814356Z","shell.execute_reply":"2023-08-24T08:56:17.825192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available and being used\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU is not available, using CPU instead\")","metadata":{"execution":{"iopub.status.busy":"2023-08-26T14:20:43.985824Z","iopub.execute_input":"2023-08-26T14:20:43.986098Z","iopub.status.idle":"2023-08-26T14:20:43.994458Z","shell.execute_reply.started":"2023-08-26T14:20:43.986075Z","shell.execute_reply":"2023-08-26T14:20:43.993457Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"GPU is available and being used\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch, gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T13:56:44.036157Z","iopub.execute_input":"2023-08-26T13:56:44.036579Z","iopub.status.idle":"2023-08-26T13:56:44.515648Z","shell.execute_reply.started":"2023-08-26T13:56:44.036535Z","shell.execute_reply":"2023-08-26T13:56:44.514532Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model = BERT().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=cfg.learning_rate)\nloss_fn = nn.MSELoss() # RMSE\nmin_val_loss = np.inf","metadata":{"execution":{"iopub.status.busy":"2023-08-26T14:13:34.319058Z","iopub.execute_input":"2023-08-26T14:13:34.319454Z","iopub.status.idle":"2023-08-26T14:13:40.747394Z","shell.execute_reply.started":"2023-08-26T14:13:34.319411Z","shell.execute_reply":"2023-08-26T14:13:40.746393Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Training loop\nmodel.train()\npatience = 0\n\nfor epoch in range(cfg.num_epochs):\n    running_loss = 0.0\n    for step, (input_ids, attention_mask, labels) in enumerate(train_dataloader):\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n\n        outputs = model(input_ids, attention_mask)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        if step % 100 == 0:\n            print(\"Epoch {}, Step {}, Loss: {}\".format(epoch+1, step, loss.item()))\n\n        running_loss += loss.item()\n\n    print(f\"Epoch {epoch+1} Loss: {running_loss / len(train_dataloader)}\")\n\n    # Validation loop\n    model.eval()\n    with torch.no_grad():\n        val_loss = 0.0\n        for val_step, (input_ids, attention_mask, labels) in enumerate(val_dataloader):\n            input_ids = input_ids.to(device)\n            attention_mask = attention_mask.to(device)\n            labels = labels.to(device)\n            \n            val_outputs = model(input_ids, attention_mask)\n            val_loss += loss_fn(val_outputs, labels) \n        avg_loss = val_loss / len(val_dataloader)\n        print(f\"Validation Loss: {avg_loss}\")\n        \n        if avg_loss < min_val_loss:\n            patience = 0\n            min_val_loss = avg_loss\n            torch.save(model.state_dict(), cfg.model_save_path)\n            print(f'saving model with score: {avg_loss}')\n            \n    patience += 1    \n    if patience >= 10:\n            print('Early Stopping trigerred on epoch: {}')\n            break\n            \n    model.train()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T14:20:57.915298Z","iopub.execute_input":"2023-08-26T14:20:57.915695Z","iopub.status.idle":"2023-08-26T15:36:36.199811Z","shell.execute_reply.started":"2023-08-26T14:20:57.915665Z","shell.execute_reply":"2023-08-26T15:36:36.198634Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch 1, Step 0, Loss: 1.4565222263336182\nEpoch 1, Step 100, Loss: 0.6990164518356323\nEpoch 1, Step 200, Loss: 0.8558355569839478\nEpoch 1, Step 300, Loss: 0.5735747218132019\nEpoch 1 Loss: 0.5617603220896469\nValidation Loss: 0.39741063117980957\nsaving model with score: 0.39741063117980957\nEpoch 2, Step 0, Loss: 0.5681753754615784\nEpoch 2, Step 100, Loss: 0.3398524522781372\nEpoch 2, Step 200, Loss: 0.39584794640541077\nEpoch 2, Step 300, Loss: 0.41541674733161926\nEpoch 2 Loss: 0.3284636493927921\nValidation Loss: 0.33838406205177307\nsaving model with score: 0.33838406205177307\nEpoch 3, Step 0, Loss: 0.32546907663345337\nEpoch 3, Step 100, Loss: 0.2607790529727936\nEpoch 3, Step 200, Loss: 0.35607147216796875\nEpoch 3, Step 300, Loss: 0.3234710097312927\nEpoch 3 Loss: 0.2614864996092233\nValidation Loss: 0.30673158168792725\nsaving model with score: 0.30673158168792725\nEpoch 4, Step 0, Loss: 0.23219060897827148\nEpoch 4, Step 100, Loss: 0.21540877223014832\nEpoch 4, Step 200, Loss: 0.2950793504714966\nEpoch 4, Step 300, Loss: 0.21725335717201233\nEpoch 4 Loss: 0.2282917708220754\nValidation Loss: 0.28560304641723633\nsaving model with score: 0.28560304641723633\nEpoch 5, Step 0, Loss: 0.2517308294773102\nEpoch 5, Step 100, Loss: 0.2291489988565445\nEpoch 5, Step 200, Loss: 0.21852026879787445\nEpoch 5, Step 300, Loss: 0.18018075823783875\nEpoch 5 Loss: 0.19314670231722525\nValidation Loss: 0.27542099356651306\nsaving model with score: 0.27542099356651306\nEpoch 6, Step 0, Loss: 0.19849728047847748\nEpoch 6, Step 100, Loss: 0.20809175074100494\nEpoch 6, Step 200, Loss: 0.2817358374595642\nEpoch 6, Step 300, Loss: 0.14896011352539062\nEpoch 6 Loss: 0.16548896223970774\nValidation Loss: 0.27696308493614197\nEpoch 7, Step 0, Loss: 0.1837070882320404\nEpoch 7, Step 100, Loss: 0.205237478017807\nEpoch 7, Step 200, Loss: 0.20322240889072418\nEpoch 7, Step 300, Loss: 0.13810589909553528\nEpoch 7 Loss: 0.1488577311023198\nValidation Loss: 0.28252604603767395\nEpoch 8, Step 0, Loss: 0.09410393238067627\nEpoch 8, Step 100, Loss: 0.19178062677383423\nEpoch 8, Step 200, Loss: 0.12031148374080658\nEpoch 8, Step 300, Loss: 0.12481461465358734\nEpoch 8 Loss: 0.12971440574522636\nValidation Loss: 0.30189597606658936\nEpoch 9, Step 0, Loss: 0.12188136577606201\nEpoch 9, Step 100, Loss: 0.18262973427772522\nEpoch 9, Step 200, Loss: 0.11181116849184036\nEpoch 9, Step 300, Loss: 0.09899488091468811\nEpoch 9 Loss: 0.12525459819974008\nValidation Loss: 0.28211548924446106\nEpoch 10, Step 0, Loss: 0.0978260263800621\nEpoch 10, Step 100, Loss: 0.20791059732437134\nEpoch 10, Step 200, Loss: 0.09440554678440094\nEpoch 10, Step 300, Loss: 0.11176864802837372\nEpoch 10 Loss: 0.11449328994684564\nValidation Loss: 0.28657206892967224\nEpoch 11, Step 0, Loss: 0.10540324449539185\nEpoch 11, Step 100, Loss: 0.1953364759683609\nEpoch 11, Step 200, Loss: 0.07905812561511993\nEpoch 11, Step 300, Loss: 0.12914344668388367\nEpoch 11 Loss: 0.10713006745930502\nValidation Loss: 0.3185971975326538\nEpoch 12, Step 0, Loss: 0.054432887583971024\nEpoch 12, Step 100, Loss: 0.14290544390678406\nEpoch 12, Step 200, Loss: 0.09236039221286774\nEpoch 12, Step 300, Loss: 0.09453970193862915\nEpoch 12 Loss: 0.09686615008310853\nValidation Loss: 0.31413325667381287\nEpoch 13, Step 0, Loss: 0.0704156905412674\nEpoch 13, Step 100, Loss: 0.1397116482257843\nEpoch 13, Step 200, Loss: 0.08453909307718277\nEpoch 13, Step 300, Loss: 0.07707180082798004\nEpoch 13 Loss: 0.08638994060560522\nValidation Loss: 0.2986918091773987\nEpoch 14, Step 0, Loss: 0.0657341256737709\nEpoch 14, Step 100, Loss: 0.1400749385356903\nEpoch 14, Step 200, Loss: 0.07410027086734772\nEpoch 14, Step 300, Loss: 0.0828111320734024\nEpoch 14 Loss: 0.08279027710967077\nValidation Loss: 0.2916679382324219\nEarly Stopping trigerred on epoch: {}\n","output_type":"stream"}]},{"cell_type":"code","source":"model = BERT()\nmodel.load_state_dict(torch.load(cfg.model_save_path))\nmodel.eval()\n\n\nenc = tokenizer(list(test['merged_text']),\n                   padding=True,\n                   truncation=True,\n                   max_length=cfg.token_max,\n                   return_tensors=\"pt\")\n\ntest_ds = TensorDataset(enc['input_ids'], enc['attention_mask'])\ntest_dataloader = torch.utils.data.DataLoader(test_ds, batch_size=16, shuffle=False)\n\n\npredictions = []\nwith torch.no_grad():\n    for input_ids, attention_mask in test_dataloader:\n        input_ids = input_ids\n        attention_mask = attention_mask\n\n        outputs = model(input_ids, attention_mask)\n        predictions.extend(outputs.cpu().numpy())\n        ","metadata":{"execution":{"iopub.status.busy":"2023-08-26T15:36:36.202055Z","iopub.execute_input":"2023-08-26T15:36:36.202612Z","iopub.status.idle":"2023-08-26T15:36:38.081300Z","shell.execute_reply.started":"2023-08-26T15:36:36.202550Z","shell.execute_reply":"2023-08-26T15:36:38.080223Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame({\n    'student_id': test['student_id'],\n    'content': [pred[0] for pred in predictions],\n    'wording': [pred[1] for pred in predictions]\n})","metadata":{"execution":{"iopub.status.busy":"2023-08-26T15:36:38.082835Z","iopub.execute_input":"2023-08-26T15:36:38.083268Z","iopub.status.idle":"2023-08-26T15:36:38.088703Z","shell.execute_reply.started":"2023-08-26T15:36:38.083225Z","shell.execute_reply":"2023-08-26T15:36:38.087769Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2023-08-26T15:36:38.091237Z","iopub.execute_input":"2023-08-26T15:36:38.091819Z","iopub.status.idle":"2023-08-26T15:36:38.123605Z","shell.execute_reply.started":"2023-08-26T15:36:38.091788Z","shell.execute_reply":"2023-08-26T15:36:38.122291Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"     student_id   content   wording\n0  000000ffffff -0.721368 -0.901968\n1  111111eeeeee -0.656841 -0.824300\n2  222222cccccc -0.626104 -0.775375\n3  333333dddddd -0.622116 -0.767138","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>-0.721368</td>\n      <td>-0.901968</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>111111eeeeee</td>\n      <td>-0.656841</td>\n      <td>-0.824300</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>222222cccccc</td>\n      <td>-0.626104</td>\n      <td>-0.775375</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>-0.622116</td>\n      <td>-0.767138</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T15:36:38.124859Z","iopub.execute_input":"2023-08-26T15:36:38.125400Z","iopub.status.idle":"2023-08-26T15:36:38.138216Z","shell.execute_reply.started":"2023-08-26T15:36:38.125364Z","shell.execute_reply":"2023-08-26T15:36:38.137275Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}